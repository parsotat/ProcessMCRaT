{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the ProcessMCRaT Example Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will walk through some of the ways that the ProcessMCRaT library can be used to process the output of a [MCRaT](https://github.com/lazzati-astro/MCRaT) simulation and conviently get and plot results quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be run interactively on your local machine if you:\n",
    "1. Clone the git repository with \n",
    "```\n",
    "git clone https://github.com/parsotat/ProcessMCRaT.git\n",
    "```\n",
    "2. After, the notebook can be accessed by navigating to the `notebook/` directory and running \n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "in the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, this notebook can be run remotely and interactively by opening it in Binder at the link: [https://mybinder.org/v2/gh/parsotat/ProcessMCRaT/HEAD?filepath=notebooks%2Fprocessmcrat_example.ipynb](https://mybinder.org/v2/gh/parsotat/ProcessMCRaT/HEAD?filepath=notebooks%2Fprocessmcrat_example.ipynb) When running the notebook on Binder, be sure to watch the memory usage of the notebook, in the upper right corner. If the memory usage exceeds 2 GB, then the notebook will crash and you will need to refresh the link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In either case the steps below will help you get an understanding of how to setup and use the ProcessMCRaT python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First we need to install the package which can be done using *pip*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the command line you would run `pip install processmcrat` or from a jupyter notebook you would run the line below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install processmcrat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. With the package now installed on your local machine or in the Binder environment we can now import the package alongside other packages that we will need to analyze a given MCRaT simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import processmcrat as pm\n",
    "import astropy.units as unit\n",
    "from astropy import constants as const\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#in your own python or ipython script you may want to set plt.ion() for interactive plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next line for interactive plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Now that we have loaded everything, we need a MCRaT simulation file to analyze. We will download one such file into this directory from the variable *40sp_down* simulation that includes polarization and cyclo-synchrotron emission and absorption. The simulation file correponds to the last frame of the hydrodynamic simulation and we will produce mock observations from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will download the mcdata file needed for this example \n",
    "import gdown\n",
    "url = 'https://drive.google.com/uc?id=12ZtMIMeLKp03Uiohfze52UBwmVJmoje0'\n",
    "output = 'mcdata_1999.h5'\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to create a MCRaT simulation load object that will hold all the information in the mcdata file. We pass the location of the directory that holds the simulation's mcdata files. If we dont pass any file directory then the library assumes that the mcdata file(s) are in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcrat_sim=pm.McratSimLoad() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the mcdata files are located in `/Volume/dir/to/mcrat/sim`, we would instead do `pm.McratSimLoad('/Volume/dir/to/mcrat/sim')`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to specify which frame we want to load and whether we want to load any other optional data such as stokes parameters, comoving four momenta, or the photon type. For our example analysis, the last frame of the hydro simulation is frame 1999 which is the last frame of the MCRaT simulation as well. Additionally, we only want to load in the stokes parameters to calculate polarizations later on. By leaving out the `read_comv` and `read_type` keywords, they are assumed to be `False`. We will see that by setting `read_stokes=True` the output of the functions that create mock observations will automatically include polarization calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcrat_sim.load_frame(1999, read_stokes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mcrat_sim` object now holds all the information for all the MCRaT photons and various quantities can be accessed of desired. We can get one of the following quantities: \n",
    "* lab frame 4 momenta (*p0, p1, p2, p3*), \n",
    "* location of each photon in cartesian coordinates of x,y, and z (*r0, r1, r2*), \n",
    "* weights (*weight*), \n",
    "* number of scatterings experienced by each photon (*scatterings*), \n",
    "* location of the photon in the original hdf5 mcdata file (*file_index*)\n",
    "* comoving fluid frame 4 momenta if loaded (*comv_p0, comv_p1, comv_p2, comv_p3*),\n",
    "* photon type if loaded (*photon_type*)\n",
    "* and the stokes parameters if loaded (*s0, s1, s2, s3*)\n",
    "\n",
    "The quantities are accessed from the `mcrat_sim` object as `mcrat_sim.loaded_photons.x`, where x is any of the italicised identifiers listed above. For example, if we want to see the photon energies we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.27059383e-08 1.26476577e-08 6.22665414e-09 ... 2.00832919e-12\n",
      " 2.74379951e-12 6.48917431e-13]\n"
     ]
    }
   ],
   "source": [
    "print(mcrat_sim.loaded_photons.p0*(const.c.cgs.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the loaded photons' 4-momenta are normalized by c, the speed of light in cgs units, which is how they are stored in the MCRaT simulations. We can get thier energies in erg simply by multiplying by c.\n",
    "\n",
    "Since the energies are something that is typically analyzed, the `mcrat_sim.loaded_photons`, which is an instance of the PhotonList class, has a method associated with it that allows us to quickly calculate the energies of the photons. It can be called as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.28964592e+01 7.89404701e+00 3.88637183e+00 ... 1.25350049e-03\n",
      " 1.71254496e-03 4.05022403e-04]\n"
     ]
    }
   ],
   "source": [
    "print(mcrat_sim.loaded_photons.get_energies()) #for comoving energies of the photons, the function is: get_comv_energies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the energy is calculated in units of keV, but by passing an applicable astropy unit to the function, the energy will be appropriately calculated. For example, to calculate the units in ergs, we do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.27059383e-08 1.26476577e-08 6.22665414e-09 ... 2.00832919e-12\n",
      " 2.74379951e-12 6.48917431e-13]\n"
     ]
    }
   ],
   "source": [
    "print(mcrat_sim.loaded_photons.get_energies(unit=unit.erg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want a wavelength, we can also do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.76892229e-01 1.57060375e+00 3.19022996e+00 ... 9.89103712e+03\n",
      " 7.23976314e+03 3.06116890e+04]\n"
     ]
    }
   ],
   "source": [
    "print(mcrat_sim.loaded_photons.get_energies(unit=unit.angstrom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An aside about units\n",
    "\n",
    "This brings us to an important aside about units used in ProcessMCRaT. The package assigns appropriate astropy units to various quantities to make sure that various calculations are done consistently. It is beneficial for the user to read some of the excellent documentation that the astropy collaboration has on their implementation of units as it will help aid in understanding the ProcessMCRaT library. This documentation can be found at [https://docs.astropy.org/en/stable/units/](https://docs.astropy.org/en/stable/units/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conduct a Mock Observation\n",
    "With a basic understanding of the McratSimLoad object and its use in loading in simulation data, we can create a mock observation with the photons. To do that we create a MockObservation object. This object, holds all the data for:\n",
    "* where an observer is located with respect to the jet axis, $\\theta_\\mathrm{v}$, \n",
    "* the acceptance angle of the observer $\\Delta \\theta$, meaning that photons that are moving towards the observer in the range [$\\theta_\\mathrm{v}-0.5\\Delta \\theta, \\theta_\\mathrm{v}+0.5\\Delta \\theta$) are considered to be detected\n",
    "* the location of the observer, $r_\\mathrm{d}$, \n",
    "* the number of frames per second in the hydrodynamic simulation that was analyzed, $\\mathrm{fps}$,\n",
    "* the number of dimensions of the hydrodynamic simulation, and\n",
    "* all of the data for photons detected by the observer at $\\theta_\\mathrm{v}$\n",
    "\n",
    "For the *40sp_down* simulation, we would make a mock observation as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation=pm.MockObservation(1, 1, 1e13, 10, mcratsimload_obj=mcrat_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the first variable passed to the observation function is $\\theta_\\mathrm{v}$ in degrees, the second is $\\Delta \\theta$ in degrees, the third is $r_\\mathrm{d}$ in cm, the fourth is fps. The last argument is the McratSimLoad object that contains all the loaded photons' data. We did not specify the number of dimensions in the call because the default is set to 2D. If the hydro simulation was in 3D, which will be supported in the future, you would have `hydrosim_dim=3` keyword as one of the arguments. \n",
    "\n",
    "The mock observation function call calculates which photons are moving towards the observer in the angle range specified previously. For these detected photons, their detection time, $t_d$, is calculated as:\n",
    "$t_d=t_\\mathrm{real} + t_p - t_j$, where $t_\\mathrm{real}$ is the lab frame time of the hydrodynamic frame that has been loaded, $t_j$ is the jet detection time which is calculated by considering a virtual photon propagating to $r_\\mathrm{d}$ at the time that the jet is initially launched. Finally, $t_p$ is the time that it will take photons to propagate towards $r_\\mathrm{d}$ from their location in the loaded MCRaT frame.\n",
    "\n",
    "Like the McratSimLoad object that we were exploring earlier, the MockObservation object that we created contains all the information for the detected photons. We can get all the same photon data as before with the addition of each photons' detection time. To access this data we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.10302427e-18 1.17673392e-18 6.61093762e-19 ... 5.72090955e-22\n",
      " 3.51041574e-22 1.38124376e-22]\n"
     ]
    }
   ],
   "source": [
    "print(observation.detected_photons.p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.71451412 11.75636985 11.7353675  ... 39.34003975 39.32799425\n",
      " 39.45023833]\n"
     ]
    }
   ],
   "source": [
    "print(observation.detected_photons.detection_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to easily save our observations, we can create event files. These event files only contain information about the detected photons at the user specified $\\theta_\\mathrm{v}$ which allow them to be smaller than the MCRaT mcdata files that can be very large and difficult to send to collaborators, for example. These files can be loaded as an observation object, allowing for continued analysis of the data. \n",
    "\n",
    "In order to create an event file, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.save_event_file('40sp_down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40sp_down_1.00e+13_1.evt   processmcrat_example.ipynb\r\n",
      "mcdata_1999.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the event file has been created. It is a text file with the .evt extension. The file name contains the identifier that we passed to the `save_event_file` function followed by $r_\\mathrm{d}$ and $\\theta_\\mathrm{v}$ for the observation. If we wanted the event file to be saved elsewhere, then we can also specify the directory using the `save_directory` optional keyword. For example, to save the file in your downloads folder you would do `observation.save_event_file('40sp_down', save_directory='~/Downloads/')`.\n",
    "\n",
    "Using the event file, you or a collaborator can load it to create the same observation object that we created above from the McratLoadSim object. Instead of running `observation=pm.MockObservation(1, 1, 1e13, 10, mcratsimload_obj=mcrat_sim)` we would do:\n",
    "```\n",
    "observation=pm.MockObservation(1, 1, 1e13, 10, id='40sp_down', directory='path/to/dir/with/eventfile/')\n",
    "```\n",
    "where we still provide the same inputs related to the observer and the hydrosimulation, but we specify the id of the observation and the directory that the event file exists in. If the event file is in the current working directory, the directory keyword can be left out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm 40sp_down_1.00e+13_1.evt #since we wont be using this file in this notebook we will remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Mock Observables\n",
    "Once we have conducted our mock observation we can create mock observables. These include producing light curves, spectra, and polarizations. We use the observation object directly to acquire these observables.\n",
    "\n",
    "#### Calculating Spectra\n",
    "In order to calculate time integrated spectra, from t=0 to t=45 s for our mock observed GRB, we simply do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tylerparsotan/Box Sync/PROCESS_MCRAT/processmcrat/mockobservations.py:787: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_Q_r = np.sqrt(var_factor * (mu_factor / mu - Q_r ** 2))\n",
      "/Users/Tylerparsotan/Box Sync/PROCESS_MCRAT/processmcrat/mockobservations.py:806: RuntimeWarning: invalid value encountered in sqrt\n",
      "  partial_pr_Ur * sigma_U_r) ** 2 + 2 * partial_pr_Qr * partial_pr_Ur * cov)\n",
      "/Users/Tylerparsotan/Box Sync/PROCESS_MCRAT/processmcrat/mockobservations.py:808: RuntimeWarning: invalid value encountered in sqrt\n",
      "  partial_phir_Ur * sigma_U_r) ** 2 + 2 * partial_phir_Qr * partial_phir_Ur * cov)\n"
     ]
    }
   ],
   "source": [
    "spectrum_dict=observation.spectrum(0, 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a dictionary object that contains all of the information in the spectrum. We can see what information there is by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['spectrum', 'spectrum_errors', 'ph_num', 'num_scatt', 'energy_bin_center', 'theta_observer', 'pol_deg', 'stokes_i', 'stokes_q', 'stokes_u', 'stokes_v', 'pol_angle', 'pol_deg_errors', 'pol_angle_errors'])\n"
     ]
    }
   ],
   "source": [
    "print(spectrum_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which shows that we have the spectrum, its errors, the number of photons in each spectral bin, the center of each energy bin that was used to construct the spectra, the stokes parameters, the calculated polarization degree and angles in each energy bin and their errors, and the observer viewing angle for this mock observation. The polarization related keys are automatically included since we had set `read_stokes=True` when we read in the MCRaT data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to access any of this information we simply do `spectrum_dict[X]` where X is any of the previously listed keys. For example, if we want to look at the spectrum and the energies that the spectral intensities correspond to we do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.36807565e+39 1.15069088e+41 3.99172198e+41 2.54927656e+42\n",
      " 6.62277000e+42 1.13376629e+43 2.47760310e+43 7.21754766e+43\n",
      " 4.97190729e+43 1.49619997e+44 7.38086794e+43 1.33447599e+44\n",
      " 1.58281109e+44 1.83923923e+44 1.73517200e+44 2.40238226e+44\n",
      " 1.87410105e+44 2.80024539e+44 2.20203239e+44 1.85754532e+44\n",
      " 1.68624011e+44 1.74963905e+44 3.77062628e+44 1.13932043e+45\n",
      " 2.76354037e+44 9.95320160e+44 6.33732200e+44 4.25013560e+45\n",
      " 4.31447309e+45 1.64380161e+46 1.87744494e+46 3.44674076e+46\n",
      " 1.04603673e+47 2.04738144e+47 4.09203657e+47 4.13228570e+47\n",
      " 6.79452354e+47 9.62918288e+47 1.67814192e+48 1.73901136e+48\n",
      " 2.22883610e+48 2.95754468e+48 3.59664549e+48 4.31893057e+48\n",
      " 5.51566588e+48 7.40655735e+48 8.09974306e+48 8.86326470e+48\n",
      " 9.84545741e+48 1.03073071e+49 1.06948128e+49 1.07519269e+49\n",
      " 9.75352329e+48 8.75459998e+48 7.39179139e+48 5.58961754e+48\n",
      " 3.93228927e+48 2.58540299e+48 1.74951601e+48 1.05313080e+48\n",
      " 6.86374915e+47 4.91414810e+47 3.10433040e+47 2.24270314e+47\n",
      " 1.36865247e+47 7.37438657e+46 4.24401214e+46 2.61692974e+46\n",
      " 1.55914187e+46 1.51832359e+46 9.12623744e+45 4.04741206e+45\n",
      " 3.71503381e+45 2.27254045e+45 4.21607534e+44 3.75022026e+44\n",
      " 3.89733080e+44 1.83801728e+44 0.00000000e+00 0.00000000e+00] erg / (keV s)\n"
     ]
    }
   ],
   "source": [
    "print(spectrum_dict['spectrum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.12201845e-07 1.41253754e-07 1.77827941e-07 2.23872114e-07\n",
      " 2.81838293e-07 3.54813389e-07 4.46683592e-07 5.62341325e-07\n",
      " 7.07945784e-07 8.91250938e-07 1.12201845e-06 1.41253754e-06\n",
      " 1.77827941e-06 2.23872114e-06 2.81838293e-06 3.54813389e-06\n",
      " 4.46683592e-06 5.62341325e-06 7.07945784e-06 8.91250938e-06\n",
      " 1.12201845e-05 1.41253754e-05 1.77827941e-05 2.23872114e-05\n",
      " 2.81838293e-05 3.54813389e-05 4.46683592e-05 5.62341325e-05\n",
      " 7.07945784e-05 8.91250938e-05 1.12201845e-04 1.41253754e-04\n",
      " 1.77827941e-04 2.23872114e-04 2.81838293e-04 3.54813389e-04\n",
      " 4.46683592e-04 5.62341325e-04 7.07945784e-04 8.91250938e-04\n",
      " 1.12201845e-03 1.41253754e-03 1.77827941e-03 2.23872114e-03\n",
      " 2.81838293e-03 3.54813389e-03 4.46683592e-03 5.62341325e-03\n",
      " 7.07945784e-03 8.91250938e-03 1.12201845e-02 1.41253754e-02\n",
      " 1.77827941e-02 2.23872114e-02 2.81838293e-02 3.54813389e-02\n",
      " 4.46683592e-02 5.62341325e-02 7.07945784e-02 8.91250938e-02\n",
      " 1.12201845e-01 1.41253754e-01 1.77827941e-01 2.23872114e-01\n",
      " 2.81838293e-01 3.54813389e-01 4.46683592e-01 5.62341325e-01\n",
      " 7.07945784e-01 8.91250938e-01 1.12201845e+00 1.41253754e+00\n",
      " 1.77827941e+00 2.23872114e+00 2.81838293e+00 3.54813389e+00\n",
      " 4.46683592e+00 5.62341325e+00 7.07945784e+00 8.91250938e+00\n",
      " 1.12201845e+01 1.41253754e+01 1.77827941e+01 2.23872114e+01\n",
      " 2.81838293e+01 3.54813389e+01 4.46683592e+01 5.62341325e+01\n",
      " 7.07945784e+01 8.91250938e+01 1.12201845e+02 1.41253754e+02\n",
      " 1.77827941e+02 2.23872114e+02 2.81838293e+02 3.54813389e+02\n",
      " 4.46683592e+02 5.62341325e+02 7.07945784e+02 8.91250938e+02\n",
      " 1.12201845e+03 1.41253754e+03 1.77827941e+03 2.23872114e+03\n",
      " 2.81838293e+03 3.54813389e+03 4.46683592e+03 5.62341325e+03\n",
      " 7.07945784e+03 8.91250938e+03 1.12201845e+04 1.41253754e+04\n",
      " 1.77827941e+04 2.23872114e+04 2.81838293e+04 3.54813389e+04\n",
      " 4.46683592e+04 5.62341325e+04 7.07945784e+04 8.91250938e+04] keV\n"
     ]
    }
   ],
   "source": [
    "print(spectrum_dict['energy_bin_center'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately see that each of these quantities have units associated with them. The units were implicitly passed to the spectrum function when we called it. To see the defaults of the spectrum method, we can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.spectrum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the docstring that pop ups, we saw that the default units of `spectrum_unit` was erg/s/keV, the energy range over which the spectrum was calculated was from [$10^{-7}$, $10^{5}$] with lograithmic step sizes of $0.1$. The default energy units are in keV, which is the normalization for the calculated spectrum. These defaults can be changed by passing in the values that we want. If we wanted the spectrum to be calculated from [$10^{2}$, $10^{8}$] eV with units of counts/s/eV then we set `spectrum_unit=unit.count/unit.s/unit.eV`, `log_energy_range=[2, 8]`, and `energy_unit=unit.eV`. This would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnitsError",
     "evalue": "The units of the energy range and the energy bin sizes have to match.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnitsError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6z/lxvsmfnd2g78f6wb49qvyr240000gn/T/ipykernel_20340/696823092.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m spect_count_dict=observation.spectrum(0, 45, spectrum_unit=unit.count/unit.s/unit.eV,\\\n\u001b[0;32m----> 2\u001b[0;31m                                       energy_range=[10**2, 10**8]*unit.eV)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspect_count_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spectrum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspect_count_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'energy_bin_center'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/astropy-4.2.1-py3.7-macosx-10.9-x86_64.egg/astropy/units/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*func_args, **func_kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;31m# Call the original function with any equivalencies in force.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0madd_enabled_equivalencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequivalencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 \u001b[0mreturn_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mvalid_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Box Sync/PROCESS_MCRAT/processmcrat/mockobservations.py\u001b[0m in \u001b[0;36mspectrum\u001b[0;34m(self, time_start, time_end, spectrum_unit, energy_range, delta_energy, photon_type, fit_spectrum, sample_num, calc_comv)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0menergy_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdelta_energy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mUnitsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The units of the energy range and the energy bin sizes have to match.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetected_photons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomv_p0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcalc_comv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnitsError\u001b[0m: The units of the energy range and the energy bin sizes have to match."
     ]
    }
   ],
   "source": [
    "spect_count_dict=observation.spectrum(0, 45, spectrum_unit=unit.count/unit.s/unit.eV,\\\n",
    "                                      energy_range=[10**2, 10**8]*unit.eV, delta_energy=1.26*unit.eV)\n",
    "print(spect_count_dict['spectrum'], spect_count_dict['energy_bin_center'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The times that are passed into the spectrum method can correspond to any times within the active period of the mock observed GRB which allows us to also create mock observed time resolved spectra. \n",
    "\n",
    "\n",
    "One of the most important things that is done with time resolved and time integrated spectra is fitting them with models (the code is only able to fit spectra with the Band and Comptonized functions at this time). **In order to do this, we have to give some information related to the fitting of the spectra. One this is done, we call the spectrum method where the units of the spectra need to be in counts/s/energy_unit. We also need to let the spectrum function that we want to do the spectral fitting.** To get a spectrum and its fitted Band or Comptonized function parameters we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.set_spectral_fit_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the code below, we can see that we just initalized the spectral energy range that we want the spectral fitting to occur over to be from 8 to 40000 keV. We also specified that we want to fit any energy bins that have greater than 10 photons in them, as that will allow us to assume that the errors in those bins are gaussian for the fitting technique used here. If you would like to change any of these parameters simply set each keyword to the values that you want when calling the `set_spectral_fit_parameters` method. For example, if we wanted to fit spectra from 8-300 eV, with either the Band or Comptonized functions, for energy bins with at least 20 photons in them we would do `observation.set_spectral_fit_parameters(spectral_fit_energy_range=[8,300], spectral_fit_energy_unit=unit.eV, approx_gaussian_error_num=20)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.set_spectral_fit_parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_dict=observation.spectrum(0, 45, spectrum_unit=unit.count/unit.s/unit.keV, fit_spectrum=True, sample_num=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spectrum_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that there are new keys for the spectral fit, the errors in the spectral fitted parameters, and the type of model that provides the superior fit (either 'b' for Band or 'c' for Comptonized function, as of now). As is shown below, the value for the 'fit' key gives another dictionary with the fitted $\\alpha$, $\\beta$ (if applicable), break energy, and normalizations. The value for the 'fit_errors' key gives another dictionary with the fitted $\\alpha$, $\\beta$ (if applicable), and break energy $1\\sigma$ errors that have been acquired by bootstrapping a number of times corresponding to the `sample_num` keyword that was passed to the spectrum method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spectrum_dict['fit'], spectrum_dict['fit_errors'])\n",
    "print(r'The best fit spectrum is a', spectrum_dict['model_use'], r'The best fit $\\alpha$ is ',\\\n",
    "      spectrum_dict['fit']['alpha'], 'with an error of', spectrum_dict['fit_errors']['alpha_errors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the spectral peak energy, we can use the included `calc_epk_error` function. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_e, peak_e_err = pm.calc_epk_error(spectrum_dict['fit']['alpha'], spectrum_dict['fit']['break_energy'],\\\n",
    "                                        alpha_error=spectrum_dict['fit_errors']['alpha_errors'],\\\n",
    "                                        break_energy_error=spectrum_dict['fit_errors']['break_energy_errors'])\n",
    "print(peak_e, peak_e_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last keyword that can be passed to the spectrum method that has not been discussed as of yet is the `photon_type`. As a default is set to `None` which means that all types of photons are included in the construction of the spectrum, both 'i' and 'c' types ([see Section 3.3 of the MCRaT documentation](https://github.com/lazzati-astro/MCRaT/blob/master/Doc/mcrat_doc.pdf)) for injected photons and cyclo-synchrotron photons. If the user wants to analyze either of these populations of photons they can set `photon_type='i'` or `photon_type='c'`.\n",
    "\n",
    "If you want to use different parameters for calculating spectra later on in your analysis, you can simply recall the observation.set_spectral_fit_parameters with new values for spectral_fit_energy_range, spectral_fit_energy_unit, and/or approx_gaussian_error_num.\n",
    "\n",
    "We have also included conenience functions to calculate the Band and Comptonized functions for a given set of parameters, thus the results of the spectral fits can be sent to these functions with energy ranges and you will be able to reconstruct the best fit spectrum. More information can be found by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.band_function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.comptonized_function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Polarization\n",
    "\n",
    "In order to calculate the time integrated polarization, we can simply do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_int_pol=observation.polarization(0,45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us another dictionary with a subset of the keys that the spectrum method provided. As is shown below, we get the stokes parameters, the polarization degree and angles, as well as the $1\\sigma$ errors of those mock observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_int_pol.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time resolved polarizations can be calculated simply by changing the time bins that the photons are collected within. If we want to calculate the polarization for a given type of photon in the simulation, we can also pass the `photon_type` keyword into our method call, the same as what we would do for calculating a spectrum.\n",
    "\n",
    "Similar to the way that we can specify an energy range to calculate the spectra within, we can also specify an energy range over which the polarization is calculated. This is done by setting the `energy_range` and `energy_unit` parameters when calling the `polarization` method. For example, if we wanted to calculated the time integrated polarization in the optical enegies from 1.5-7.7 eV then we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(observation.polarization(0,45, energy_range=[1.5,7.7]*unit.eV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Light Curves\n",
    "\n",
    "Calculating light curves is just as easy as calculating spectra and polarization. To get the light curve that an observer located at $\\theta_\\mathrm{v}=1^\\circ$ would detect from our *40sp_down* simulated GRB, from 10 s after the jet was launched to 40 s after the jet was launched in uniform time bins, we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurve_dict=observation.lightcurve(time_start=10, time_end=40, dt=0.2)\n",
    "print(lightcurve_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the various keys in the dictionary we can see that we get similar keys as from the previous dictionaries. The difference here is that the output quantities are functions of time. The times that we get define the time bins that photons are collected within to produce the lightcurves, polarization, and other quantities. \n",
    "\n",
    "If we wanted to produce the light curve using variable time bins, we can set `variable_t_bins=True` such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurve_dict=observation.lightcurve(time_start=10, time_end=40, dt=0.2, variable_t_bins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alteratively, if you have an array that defines the time bins that you would like the light curve and other quantities to be calculated from, you can pass that information instead as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.arange(10, 40, 2)\n",
    "lightcurve_dict=observation.lightcurve(time_array=t)\n",
    "print(lightcurve_dict['times'])\n",
    "print(lightcurve_dict['lightcurve'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the times have been used to calculate the lightcurve. The default calculation of the lightcurve produces values that have units of erg/s however the light curve can also be set to counts/s by setting `lc_unit=unit.count/unit.s`. These light curves were calculated without any energy cuts making them bolometric light curves however, we can also calculate the light curve for a specific energy range of photons. For example if we wanted to calculate the light curve from 10-1000 eV we would do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurve_dict=observation.lightcurve(time_start=10, time_end=40, dt=0.2, energy_range=[10, 1000]*unit.eV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each time bin we can also calculate the time resolved spectrum and fit the spectra from each time bin. In order to do this, we set `fit_spectrum=True`. This can take a little while to calculate based on the `spectral_sample_num` value. This is identical to the `sample_num` keyword that gets passed to the `spectrum` method. To minimize the wait time in this notebook, we have decreased the number of time bins that will have spectra that need to be fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurve_dict=observation.lightcurve(time_start=10, time_end=40, dt=1, fit_spectrum=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lightcurve_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that there are new keys in the returned dictionary related to the spectral fittings. We can access the fitted alphas by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lightcurve_dict['fit']['alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With producing these mock observables, it becomes tedious to constantly enter a certain spectral energy range that you would like the spectra to be calculated within, or light curve energy range, or detected polarization energy range to simulate what energy ranges a given instrument would make its measurements in. In order to simplify this, the ProcessMCRaT code allows you to create an instrument with these parameters defined. Then, we can load this instrument into each of our observation objects which will automatically apply the instrumental energy constraints for each mock observable that is produced. \n",
    "\n",
    "Lets create a Polar-2/Fermi mash-up instrument, which would measure polarization from 20-800 keV, spectra from 8 keV-40 MeV, and light curves from 20-800 keV as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst=pm.Instrument(name='Fermi+Polar', polarization_energy_range=[20,800]*unit.keV,\\\n",
    "                  spectral_energy_range=[8,40000]*unit.keV, lightcurve_energy_range=[20,800]*unit.keV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any of the fields are not specified and left off of the call to create the instrument, then they will be ignored and the calculations for those mock observables will default to being integrated over energy. For example if we did `pm.Instrument(name='Fermi+Polar', polarization_energy_range=[20,800], polarization_energy_unit=unit.keV, spectral_energy_range=[8,40000], spectral_energy_unit=unit.keV` then the light cuves that we could calculate after loading the instruent into our observation object would be bolometric light curves. If we left off `spectral_energy_range=[8,40000]` and `spectral_energy_unit=unit.keV` then the spectra would be calculted for the default energy ranges in the spectrum method.\n",
    "\n",
    "Now that we have our instrument, we can tell our observation object that we want to use this instrument by loading it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.load_instrument(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the instrument loaded we can recalcalculate some of our mock observables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_spec_dict=observation.spectrum(0, 45, spectrum_unit=unit.count/unit.s/unit.keV, fit_spectrum=True, sample_num=1e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above call calculates our time integrated light curve from 8 keV-40 MeV and it fits our spectrum from 8 keV-40 MeV due to the fact that we specified this energy range to conduct our spectral fitting within when we ran `observation.set_spectral_fit_parameters()`.\n",
    "\n",
    "After calculating the light curves, polarization, and spectra using the instrument, you can unload i from the observation by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.unload_instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, while having the instrument loaded, you want to explore what a given mock obervable would look like in a different energy range, you can specify that in the method call and it will override the instrumental energy constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plotting Mock Observables\n",
    "\n",
    "Now that we have explored some of the mock observables that can be created with a given MockObservable object, we can plot some of the results that we have acquired with some of the convenience functions that are included with ProcessMCRaT. These functions can be used to quickly explore and plot data with nearly publication ready plots.\n",
    "\n",
    "The spectrum that we have just acquired can be plotted by calling `pm.plot_spectrum`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_spectrum(inst_spec_dict); #if the figure is a bit small with the labels cutoff, you can drag the bottom right \\\n",
    "                                #  corner of the plot to make it larger\n",
    "plt.pause(1)\n",
    "print(inst_spec_dict['fit']['alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the spectrum was indeed calculated within the limits that we had specified and the figure has the correct units that we specified for the calculations already. Lets also look at the best fit function and assess its fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm.plot_spectrum(inst_spec_dict, plot_fit=True);\n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the entire time integrated spectrum in erg/s/keV that we calculated much earlier with polarization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes=pm.plot_spectrum(spectrum_dict, plot_polarization=True);\n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned values are handles to the figure and the axes of the plot which allows you to modify the plot to your liking. Lets take our fitted spectrum and change the hard-to-see black line to something more visible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes=pm.plot_spectrum(inst_spec_dict, plot_fit=True)\n",
    "lines=axes.get_lines()\n",
    "lines[2].set_color('r')\n",
    "fig.canvas.draw()\n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one other keyword that can be passed to the `plot_spectrum` function. This is the `photon_num_min` keyword and it tells the function to plot the points that had at least $n$ photons in the energy bin. The default value for $n$ is 10, which also correponds to the default value of the number of photons needed to assume that a spectral bin had gaussian errors to conduct the fitting when we called the `set_spectral_fit_parameters` method.\n",
    "\n",
    "All quantities can be plotted simply by setting each to `True` such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes=pm.plot_spectrum(inst_spec_dict, plot_fit=True, plot_polarization=True)\n",
    "lines=axes[0].get_lines()\n",
    "lines[2].set_color('r')\n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can explore the `plot_lightcurve` function which can plot multiple light curves at the same time, when passed in as a list, and also simultaneously plot the polarization and time resolved spectral fitted parameters for the first light curve in the list that is passed in.\n",
    "\n",
    "We can plot our light curve with polarization and the spectral fitted parameters by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_lightcurve([lightcurve_dict], plot_polarization=True, plot_spectral_params=True);\n",
    "plt.pause(1)\n",
    "print(lightcurve_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have multiple light curves that we want to plot then the first light curve with its fitted spectral parameters and calculated polarizations are passed. These light curves are then all normalized to their maximal values L$_\\mathrm{max}$. \n",
    "\n",
    "Like the `plot_spectrum` function, the `plot_lightcurve` function outputs the figure and axes object arrays that allow you to make modifications to the plot as you would like.\n",
    "\n",
    "With a number of spectra, you can also produce histograms of the best fit spectral parameters using the `plot_spectral_fit_hist` function. It takes a list of light curve observations where time resolved spectral fitting has been done and it plots the corresponding histograms. This function can also take a dataset of observational spectral parameters such as what is given by the `get_FERMI_best_data` function. In order to plot these histograms we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_spectral_fit_hist([lightcurve_dict], observational_data=pm.get_FERMI_best_data());\n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the array of figures and axes that allow you to modify each plot to your liking. Additionally, it returns arrays of all the fitted spectral parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ProcessMCRaT library makes it easy to analyze data for a number of observer viewing angles, wavelenghts, or any thing else that you are interested in. It is easy to make a list of MockObservation objects that you can then do a number of analyses on. For example, we may want to compare our MCRaT simulation to a number of observational relationships. Lets do this for the Yonetoku, Golenetskii, and Amati relationships.\n",
    "\n",
    "First we create a list of observations for observers at different viewing angles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_list=[]\n",
    "for i in range(1,10): \n",
    "    observation_list.append(pm.MockObservation(i, 1, 1e13, 10, mcratsimload_obj=mcrat_sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make our lists of mock observations for the spectra, polarizations, and light curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict_list=[];lc_dict_list=[];pol_dict_list=[]  \n",
    "for i in observation_list: \n",
    "    i.set_spectral_fit_parameters()  \n",
    "    spec_dict_list.append(i.spectrum(0, 45,spectrum_unit=unit.count/unit.s/unit.keV , fit_spectrum=True)) \n",
    "    lc_dict_list.append(i.lightcurve(time_start=10, time_end=40, dt=1) ) #dt=1 here for plotting the Yonetoku relation\n",
    "    pol_dict_list.append(i.polarization(0, 45)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the mock observations along the Yonetoku, Golenetskii, and Amati relationships using the `plot_yonetoku_relationship`, `plot_golenetskii_relationship`, and `plot_amati_relationship` functions. Each function returns the figure, axes, and either the colorbar or line objects that are in the plot so the user can customize their plot as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_yonetoku_relationship(spec_dict_list, lc_dict_list, plot_polarization=True, polarization_list=pol_dict_list,\\\n",
    "                              labels=[r'40sp_down']); #make sure that the light curves are binned into 1 s bins\n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Yonetoku case we are able to plot the results of the *40sp_down* simulation for a number of different viewing angles with bolometric polarization alongside the yonetoku relationship which we have acquired from the `get_yonetoku_relationship` function, and some observational GRB data. The polarization parameters and label parameters are optional. If we leave them off, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_yonetoku_relationship(spec_dict_list, lc_dict_list);#make sure that the light curves are binned into 1 s bins\n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass in a list of lists, where each individual list corresponds to a different simulation and the number of elements in the list correspond to the various observer viewing angles. In this case, the number of labels corresponds to the number of sub-lists that are in the main list that is passed to the function. For example we can have a list of 2 sublists, one sublist is the *40sp_down* results for observers located from 1-9$^\\circ$ while the second sublist could be for another simulation (e.g our *16TI* simulation) for observers located from 1-15$^\\circ$.\n",
    "\n",
    "The function also takes an input function that defined the Yonetoku relationship itself, with no passed parameters, the upper limit, when '+' is passed to it, and the lower limit, when '-' is passed, similar to the formatting of the `get_yonetoku_relationship` function.\n",
    "\n",
    "To plot the Golenetskii relationship we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_golenetskii_relationship(lightcurve_dict, luminosity_cutoff=1e50);\n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where we can pass a list of light curve dictionaries that correspond to various observer viewing angles for a given MCRaT simulation. We can also pass in a label for the simulation, a function that defines the golenetskii realtionship and its upper and lower limits, and a luminosity cutoff that may coincide with observational analyses. In the case of the function that defines the golenetskii relationship, it should be formatted the same as the `get_golenetskii_relationship` which takes no argument to return the relationship itself, but takes the `+` argument to return some upper limit, and a `-` argument to return a lower limit on the relationship. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.get_golenetskii_relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the Amati relationship we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_amati_relationship([spec_dict_list, spec_dict_list[:5]], [lc_dict_list, lc_dict_list[:5]],\\\n",
    "                           labels=['40sp_down', r'40sp_down 1-5$^\\circ$']); \n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where we have plotted the *40sp_down* simulation and created a 'different' simulation defined as the first 5 viewing angles of the *40sp_down* simulation. This allows us to show the fact that the `plot_amati_relationship` function has the same functionality as the `plot_yonetoku_relationship` where it can plot points from various simulation sets based on its inputs being lists of lists.\n",
    "\n",
    "The `plot_amati_relationship` can also be passed a function that defines the upper and lower limits of the reationship similar to the `get_amati_relationship` function that is included in ProcessMCRaT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.get_amati_relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to these plots that allow us to explore how well the MCRaT simulations reproduce observational relationships relating spectral energies and the light curves, we can explore the polarization properties as well.\n",
    "\n",
    "We can plot the polarization degree and angle as a function of $\\theta_\\mathrm{v}$ with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_polarization_observer_angle(pol_dict_list, plot_pol_angle=True); \n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And like some of the previous functions that we have covered, the `plot_polarization_observer_angle` can plot multiple simulations at the same time by passing it a list of sublists for each MCRaT simulation. This can look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_polarization_observer_angle([pol_dict_list, pol_dict_list[:3]], labels=['original', 'test_sim']);\n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the polarization as a function of the spectral peak energy using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_polarization_peak_energy(spec_dict_list, pol_dict_list); \n",
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these plots we can also add our own observational points to compare to. For example, lets calculate the optical polarization within the Swift white band and compare it to an observation made by [Troja et. al.](https://www.nature.com/articles/nature23289) where they measured a GRB's lower limit optical polarization to be 8% and its spectral peak energy to be 140 keV.\n",
    "\n",
    "To save memory we will delete some variables. In the following line, we summarize some of the important points of using the ProcessMCRaT package to analyze MCRaT data and produce the optical polarization comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del inst_spec_dict, lightcurve_dict, spect_count_dict, spectrum_dict, time_int_pol, t, mcrat_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcrat_sim=pm.McratSimLoad() \n",
    "mcrat_sim.load_frame(1999, read_stokes=True)\n",
    "\n",
    "#create the instrument that we need \n",
    "inst=pm.Instrument(name='Swift_white',polarization_energy_range=[1597,7820]*unit.angstrom) \n",
    "\n",
    "#create our observations for each observer viewing angle\n",
    "observation_list=[]\n",
    "for i in range(1,10): \n",
    "    observation_list.append(pm.MockObservation(i, 1, 1e13, 10, mcratsimload_obj=mcrat_sim))\n",
    "    \n",
    "#load the instrument and specify the spectral fitting parameters to make the calculations\n",
    "spec_dict_list=[];pol_dict_list=[]  \n",
    "for i in observation_list: \n",
    "    i.load_instrument(inst)\n",
    "    i.set_spectral_fit_parameters()  \n",
    "    spec_dict_list.append(i.spectrum(0, 45,spectrum_unit=unit.count/unit.s/unit.keV , fit_spectrum=True)) \n",
    "    pol_dict_list.append(i.polarization(0, 45)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=pm.plot_polarization_peak_energy(spec_dict_list, pol_dict_list, labels=['40sp_down Swift White']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=pm.plot_polarization_peak_energy(spec_dict_list, pol_dict_list, labels=['40sp_down Swift White']) \n",
    "troja_data_epk=140\n",
    "troja_data_epk_errors=[30,40]\n",
    "troja_data_pol=8\n",
    "lolims=np.array([1], dtype=bool) #this says that the polarization is a lower limit\n",
    "ax.errorbar(troja_data_epk, troja_data_pol, xerr=np.array([troja_data_epk_errors]).T, yerr=5, lolims=lolims, color='k', zorder=4, markersize=10)\n",
    "ax.set_ylabel(r'$\\Pi_\\mathrm{opt}$ (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip(spec_dict_list,pol_dict_list):\n",
    "    print(pm.calc_epk_error(i['fit']['alpha'], i['fit']['break_energy'].value, \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\talpha_error=i['fit_errors']['alpha_errors'], \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbreak_energy_error=i['fit_errors']['break_energy_errors'].value), j['pol_deg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
